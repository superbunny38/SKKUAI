{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Confusion Matrix 보정",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion Matrix 보정"
      ],
      "metadata": {
        "id": "ziytM6QrmLHz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "사용되는 data들은 class간 유사도가 굉장히 높다. 육안으로 구분이 어려울 정도이므로 confusing 할 가능성이 높다.\n",
        "\n",
        "두 이미지 간 관계를 KL-Divergence로 정의하고, loss function에 가중치를 더하여 CM(Confusion Matrix) 계산 과정에서의 정확도를 보정한다.\n",
        "\n",
        "즉, 모델이 학습 데이터를 완전히 암기하기 전 단계의 예측값과 정답을 이용하여 CM을 만든 뒤 CR을 산출하여 학습에 이용한다.\n",
        "\n",
        "입력 이미지에 대한 모델의 예측값 ŷ 와 정답값 y를 이용하여 CM을 만든다.\n",
        "\n",
        "이후 아래 식을 이용하여 CR을 구하고 loss function에 가중치를 더해 backpropagation을 수행한다.\n",
        "\n",
        "CM의 행과 열은 각각 정답값과 예측값을 의미하며 i와 j는 학습할 때 클래스에 부여된 번호이다."
      ],
      "metadata": {
        "id": "xGUVzy1nmRDl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음은 간단한 python pseudo code이다."
      ],
      "metadata": {
        "id": "zKoaxtBsp4KZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P24aHWTVmBc8"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "from scipy.stats import truncnorm, entropy\n",
        "\n",
        "import math\n",
        "import copy\n",
        "\n",
        "# Random sampling (Normal distribution)\n",
        "def get_truncated_normal(mean=2, sd=1, low=0, upp=5):\n",
        "    return truncnorm(\n",
        "        (low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)\n",
        "\n",
        "k = 3\n",
        "epochs = 30\n",
        "mini_batch = 32\n",
        "num_data = 2000\n",
        "prev = []\n",
        "\n",
        "for n in range(epochs):\n",
        "    y_t = get_truncated_normal()\n",
        "    y_p = get_truncated_normal()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    for i in range(num_data):\n",
        "        y_true.append(math.floor(y_t.rvs()))\n",
        "        y_pred.append(math.floor(y_p.rvs()))\n",
        "\n",
        "    CM = [[0]*5 for _ in range(5)]\n",
        "    CR = [[0.0]*5 for _ in range(5)]\n",
        "\n",
        "    if n >= 1:\n",
        "        for i in range(5):\n",
        "            for j in range(5):\n",
        "                if i != j:\n",
        "                    CR[i][j] = float(prev[i][j]) / float(prev[i][j] + prev[j][i])\n",
        "                else:\n",
        "                    CR[i][j] = 0\n",
        "\n",
        "\t\t# Especially, regarding mini_batch indexing -> (n*mini_batch + m)\n",
        "\t\t# CM = confusion_matrix(y_true, y_pred)  : easy way\n",
        "    for m in range(mini_batch): \n",
        "        y = y_true[n*mini_batch + m] # true\n",
        "        y_hat = y_pred[n*mini_batch + m] # predict\n",
        "        CM[y][y_hat] += 1\n",
        "\n",
        "        if n > 1:\n",
        "            for i in range(mini_batch):\n",
        "                if y != y_hat:\n",
        "\t\t\t\t\t\t\t\t\t\t# Calibrate the loss when calculating.\n",
        "                    Loss = Loss + k * Loss * entropy([CR[y][y_hat], CR[y_hat][y]], base=2)\n",
        "\n",
        "    prev = copy.deepcopy(CM)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "h4hTiiTipvCp"
      }
    }
  ]
}